{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_logging():\n",
    "    \"\"\"Custom logging format for better readability.\"\"\"\n",
    "    level_mapping = {\"DEBUG\": \"D\", \"INFO\": \"I\", \"WARNING\": \"W\", \"ERROR\": \"E\", \"CRITICAL\": \"C\"}\n",
    "\n",
    "    class CustomFormatter(logging.Formatter):\n",
    "        def format(self, record):\n",
    "            record.levelname = level_mapping.get(record.levelname, record.levelname)\n",
    "            return super().format(record)\n",
    "\n",
    "    formatter = CustomFormatter(\n",
    "        fmt=\"%(asctime)s.%(msecs)03d [%(levelname)s] %(message)-80s (%(process)d:%(filename)s:%(lineno)s)\",\n",
    "        datefmt=\"%H:%M:%S\",\n",
    "    )\n",
    "\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.handlers[0].setFormatter(formatter)\n",
    "\n",
    "\n",
    "def init_wandb(config: _config.TrainConfig, *, resuming: bool, log_code: bool = False, enabled: bool = True):\n",
    "    if not enabled:\n",
    "        wandb.init(mode=\"disabled\")\n",
    "        return\n",
    "\n",
    "    ckpt_dir = config.checkpoint_dir\n",
    "    if not ckpt_dir.exists():\n",
    "        raise FileNotFoundError(f\"Checkpoint directory {ckpt_dir} does not exist.\")\n",
    "    if resuming:\n",
    "        run_id = (ckpt_dir / \"wandb_id.txt\").read_text().strip()\n",
    "        wandb.init(id=run_id, resume=\"must\", project=config.project_name)\n",
    "    else:\n",
    "        wandb.init(\n",
    "            name=config.exp_name,\n",
    "            config=dataclasses.asdict(config),\n",
    "            project=config.project_name,\n",
    "        )\n",
    "        (ckpt_dir / \"wandb_id.txt\").write_text(wandb.run.id)\n",
    "\n",
    "    if log_code:\n",
    "        wandb.run.log_code(epath.Path(__file__).parent.parent)\n",
    "\n",
    "\n",
    "def _load_weights_and_validate(loader: _weight_loaders.WeightLoader, params_shape: at.Params) -> at.Params:\n",
    "    \"\"\"Loads and validates the weights. Returns a loaded subset of the weights.\"\"\"\n",
    "    loaded_params = loader.load(params_shape)\n",
    "    at.check_pytree_equality(expected=params_shape, got=loaded_params, check_shapes=True, check_dtypes=True)\n",
    "\n",
    "    # Remove jax.ShapeDtypeStruct from the loaded params. This makes sure that only the loaded params are returned.\n",
    "    return traverse_util.unflatten_dict(\n",
    "        {k: v for k, v in traverse_util.flatten_dict(loaded_params).items() if not isinstance(v, jax.ShapeDtypeStruct)}\n",
    "    )\n",
    "\n",
    "\n",
    "@at.typecheck\n",
    "def init_train_state(\n",
    "    config: _config.TrainConfig, init_rng: at.KeyArrayLike, mesh: jax.sharding.Mesh, *, resume: bool\n",
    ") -> tuple[training_utils.TrainState, Any]:\n",
    "    tx = _optimizer.create_optimizer(config.optimizer, config.lr_schedule, weight_decay_mask=None)\n",
    "\n",
    "    def init(rng: at.KeyArrayLike, partial_params: at.Params | None = None) -> training_utils.TrainState:\n",
    "        rng, model_rng = jax.random.split(rng)\n",
    "        # initialize the model (and its parameters).\n",
    "        model = config.model.create(model_rng)\n",
    "\n",
    "        # Merge the partial params into the model.\n",
    "        if partial_params is not None:\n",
    "            graphdef, state = nnx.split(model)\n",
    "            # This will produce an error if the partial params are not a subset of the state.\n",
    "            state.replace_by_pure_dict(partial_params)\n",
    "            model = nnx.merge(graphdef, state)\n",
    "\n",
    "        params = nnx.state(model)\n",
    "        # Convert frozen params to bfloat16.\n",
    "        params = nnx_utils.state_map(params, config.freeze_filter, lambda p: p.replace(p.value.astype(jnp.bfloat16)))\n",
    "\n",
    "        return training_utils.TrainState(\n",
    "            step=0,\n",
    "            params=params,\n",
    "            model_def=nnx.graphdef(model),\n",
    "            tx=tx,\n",
    "            opt_state=tx.init(params.filter(config.trainable_filter)),\n",
    "            ema_decay=config.ema_decay,\n",
    "            ema_params=None if config.ema_decay is None else params,\n",
    "        )\n",
    "\n",
    "    train_state_shape = jax.eval_shape(init, init_rng)\n",
    "    state_sharding = sharding.fsdp_sharding(train_state_shape, mesh, log=True)\n",
    "\n",
    "    if resume:\n",
    "        return train_state_shape, state_sharding\n",
    "\n",
    "    partial_params = _load_weights_and_validate(config.weight_loader, train_state_shape.params.to_pure_dict())\n",
    "    replicated_sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec())\n",
    "\n",
    "    # Initialize the train state and mix in the partial params.\n",
    "    train_state = jax.jit(\n",
    "        init,\n",
    "        donate_argnums=(1,),  # donate the partial params buffer.\n",
    "        in_shardings=replicated_sharding,\n",
    "        out_shardings=state_sharding,\n",
    "    )(init_rng, partial_params)\n",
    "\n",
    "    return train_state, state_sharding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@at.typecheck\n",
    "def train_step(\n",
    "    config: _config.TrainConfig,\n",
    "    rng: at.KeyArrayLike,\n",
    "    state: training_utils.TrainState,\n",
    "    batch: tuple[_model.Observation, _model.Actions],\n",
    ") -> tuple[training_utils.TrainState, dict[str, at.Array]]:\n",
    "    model = nnx.merge(state.model_def, state.params)\n",
    "    model.train()\n",
    "\n",
    "    @at.typecheck\n",
    "    def loss_fn(\n",
    "        model: _model.BaseModel, rng: at.KeyArrayLike, observation: _model.Observation, actions: _model.Actions\n",
    "    ):\n",
    "        chunked_loss = model.compute_loss(rng, observation, actions, train=True)\n",
    "        return jnp.mean(chunked_loss)\n",
    "\n",
    "    train_rng = jax.random.fold_in(rng, state.step)\n",
    "    observation, actions = batch\n",
    "\n",
    "    # Filter out frozen params.\n",
    "    diff_state = nnx.DiffState(0, config.trainable_filter)\n",
    "    loss, grads = nnx.value_and_grad(loss_fn, argnums=diff_state)(model, train_rng, observation, actions)\n",
    "\n",
    "    params = state.params.filter(config.trainable_filter)\n",
    "    updates, new_opt_state = state.tx.update(grads, state.opt_state, params)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "\n",
    "    # Update the model in place and return the new full state.\n",
    "    nnx.update(model, new_params)\n",
    "    new_params = nnx.state(model)\n",
    "\n",
    "    new_state = dataclasses.replace(state, step=state.step + 1, params=new_params, opt_state=new_opt_state)\n",
    "    if state.ema_decay is not None:\n",
    "        new_state = dataclasses.replace(\n",
    "            new_state,\n",
    "            ema_params=jax.tree.map(\n",
    "                lambda old, new: state.ema_decay * old + (1 - state.ema_decay) * new, state.ema_params, new_params\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    # Filter out params that aren't kernels.\n",
    "    kernel_params = nnx.state(\n",
    "        model,\n",
    "        nnx.All(\n",
    "            nnx.Param,\n",
    "            nnx.Not(nnx_utils.PathRegex(\".*/(bias|scale|pos_embedding|input_embedding)\")),\n",
    "            lambda _, x: x.value.ndim > 1,\n",
    "        ),\n",
    "    )\n",
    "    info = {\n",
    "        \"loss\": loss,\n",
    "        \"grad_norm\": optax.global_norm(grads),\n",
    "        \"param_norm\": optax.global_norm(kernel_params),\n",
    "    }\n",
    "    return new_state, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config: _config.TrainConfig):\n",
    "    init_logging()\n",
    "    logging.info(f\"Running on: {platform.node()}\")\n",
    "\n",
    "    if config.batch_size % jax.device_count() != 0:\n",
    "        raise ValueError(\n",
    "            f\"Batch size {config.batch_size} must be divisible by the number of devices {jax.device_count()}.\"\n",
    "        )\n",
    "\n",
    "    jax.config.update(\"jax_compilation_cache_dir\", str(epath.Path(\"~/.cache/jax\").expanduser()))\n",
    "\n",
    "    rng = jax.random.key(config.seed)\n",
    "    train_rng, init_rng = jax.random.split(rng)\n",
    "\n",
    "    mesh = sharding.make_mesh(config.fsdp_devices)\n",
    "    data_sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(sharding.DATA_AXIS))\n",
    "    replicated_sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec())\n",
    "\n",
    "    checkpoint_manager, resuming = _checkpoints.initialize_checkpoint_dir(\n",
    "        config.checkpoint_dir,\n",
    "        keep_period=config.keep_period,\n",
    "        overwrite=config.overwrite,\n",
    "        resume=config.resume,\n",
    "    )\n",
    "    init_wandb(config, resuming=resuming, enabled=config.wandb_enabled)\n",
    "\n",
    "    data_loader = _data_loader.create_data_loader(\n",
    "        config,\n",
    "        sharding=data_sharding,\n",
    "        num_workers=config.num_workers,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    data_iter = iter(data_loader)\n",
    "    batch = next(data_iter)\n",
    "    logging.info(f\"Initialized data loader:\\n{training_utils.array_tree_to_info(batch)}\")\n",
    "\n",
    "    train_state, train_state_sharding = init_train_state(config, init_rng, mesh, resume=resuming)\n",
    "    jax.block_until_ready(train_state)\n",
    "    logging.info(f\"Initialized train state:\\n{training_utils.array_tree_to_info(train_state.params)}\")\n",
    "\n",
    "    if resuming:\n",
    "        train_state = _checkpoints.restore_state(checkpoint_manager, train_state, data_loader)\n",
    "\n",
    "    ptrain_step = jax.jit(\n",
    "        functools.partial(train_step, config),\n",
    "        in_shardings=(replicated_sharding, train_state_sharding, data_sharding),\n",
    "        out_shardings=(train_state_sharding, replicated_sharding),\n",
    "        donate_argnums=(1,),\n",
    "    )\n",
    "\n",
    "    start_step = int(train_state.step)\n",
    "    pbar = tqdm.tqdm(\n",
    "        range(start_step, config.num_train_steps),\n",
    "        initial=start_step,\n",
    "        total=config.num_train_steps,\n",
    "        dynamic_ncols=True,\n",
    "    )\n",
    "\n",
    "    # infos = []\n",
    "    # for step in pbar:\n",
    "    #     with sharding.set_mesh(mesh):\n",
    "    #         train_state, info = ptrain_step(train_rng, train_state, batch)\n",
    "    #     infos.append(info)\n",
    "    #     if step % config.log_interval == 0:\n",
    "    #         stacked_infos = common_utils.stack_forest(infos)\n",
    "    #         reduced_info = jax.device_get(jax.tree.map(jnp.mean, stacked_infos))\n",
    "    #         info_str = \", \".join(f\"{k}={v:.4f}\" for k, v in reduced_info.items())\n",
    "    #         pbar.write(f\"Step {step}: {info_str}\")\n",
    "    #         wandb.log(reduced_info, step=step)\n",
    "    #         infos = []\n",
    "    #     batch = next(data_iter)\n",
    "\n",
    "    #     if (step % config.save_interval == 0 and step > start_step) or step == config.num_train_steps - 1:\n",
    "    #         _checkpoints.save_state(checkpoint_manager, train_state, data_loader, step)\n",
    "\n",
    "    # logging.info(\"Waiting for checkpoint manager to finish\")\n",
    "    checkpoint_manager.wait_until_finished()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_test(config: _config.TrainConfig):\n",
    "    init_logging()\n",
    "    logging.info(f\"Running on: {platform.node()}\")\n",
    "\n",
    "    if config.batch_size % jax.device_count() != 0:\n",
    "        raise ValueError(\n",
    "            f\"Batch size {config.batch_size} must be divisible by the number of devices {jax.device_count()}.\"\n",
    "        )\n",
    "\n",
    "    jax.config.update(\"jax_compilation_cache_dir\", str(epath.Path(\"~/.cache/jax\").expanduser()))\n",
    "\n",
    "    rng = jax.random.key(config.seed)\n",
    "    train_rng, init_rng = jax.random.split(rng)\n",
    "\n",
    "    mesh = sharding.make_mesh(config.fsdp_devices)\n",
    "    data_sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(sharding.DATA_AXIS))\n",
    "    replicated_sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec())\n",
    "\n",
    "    checkpoint_manager, resuming = _checkpoints.initialize_checkpoint_dir(\n",
    "        config.checkpoint_dir,\n",
    "        keep_period=config.keep_period,\n",
    "        overwrite=config.overwrite,\n",
    "        resume=config.resume,\n",
    "    )\n",
    "    init_wandb(config, resuming=resuming, enabled=config.wandb_enabled)\n",
    "\n",
    "    data_loader = _data_loader.create_data_loader(\n",
    "        config,\n",
    "        sharding=data_sharding,\n",
    "        num_workers=config.num_workers,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    data_iter = iter(data_loader)\n",
    "    batch = next(data_iter)\n",
    "    logging.info(f\"Initialized data loader:\\n{training_utils.array_tree_to_info(batch)}\")\n",
    "\n",
    "    train_state, train_state_sharding = init_train_state(config, init_rng, mesh, resume=resuming)\n",
    "    jax.block_until_ready(train_state)\n",
    "    logging.info(f\"Initialized train state:\\n{training_utils.array_tree_to_info(train_state.params)}\")\n",
    "\n",
    "    if resuming:\n",
    "        train_state = _checkpoints.restore_state(checkpoint_manager, train_state, data_loader)\n",
    "\n",
    "    ptrain_step = jax.jit(\n",
    "        functools.partial(train_step, config),\n",
    "        in_shardings=(replicated_sharding, train_state_sharding, data_sharding),\n",
    "        out_shardings=(train_state_sharding, replicated_sharding),\n",
    "        donate_argnums=(1,),\n",
    "    )\n",
    "\n",
    "    start_step = int(train_state.step)\n",
    "    pbar = tqdm.tqdm(\n",
    "        range(start_step, config.num_train_steps),\n",
    "        initial=start_step,\n",
    "        total=config.num_train_steps,\n",
    "        dynamic_ncols=True,\n",
    "    )\n",
    "\n",
    "    infos = []\n",
    "    # for step in pbar:\n",
    "    #     with sharding.set_mesh(mesh):\n",
    "    #         train_state, info = ptrain_step(train_rng, train_state, batch)\n",
    "    #     infos.append(info)\n",
    "    #     if step % config.log_interval == 0:\n",
    "    #         stacked_infos = common_utils.stack_forest(infos)\n",
    "    #         reduced_info = jax.device_get(jax.tree.map(jnp.mean, stacked_infos))\n",
    "    #         info_str = \", \".join(f\"{k}={v:.4f}\" for k, v in reduced_info.items())\n",
    "    #         pbar.write(f\"Step {step}: {info_str}\")\n",
    "    #         wandb.log(reduced_info, step=step)\n",
    "    #         infos = []\n",
    "    #     batch = next(data_iter)\n",
    "\n",
    "    #     if (step % config.save_interval == 0 and step > start_step) or step == config.num_train_steps - 1:\n",
    "    #         _checkpoints.save_state(checkpoint_manager, train_state, data_loader, step)\n",
    "\n",
    "    logging.info(\"Waiting for checkpoint manager to finish\")\n",
    "    checkpoint_manager.wait_until_finished()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭─ </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Unrecognized options</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ──────────────────────────────────────────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> Unrecognized options: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> --Session.signature-scheme=\"hmac-sha256\" --Session.key=b\"07992966-17c4-4623-9c3a-c1536aa9b1db\" --shell=9002     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> --transport=\"tcp\" --iopub=9004 --f=/root/.local/share/jupyter/runtime/kernel-v2-3168gicBIIWBpmuv.json           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> For full helptext, run <span style=\"font-weight: bold\">ipykernel_launcher.py --help</span>                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[91m╭─\u001b[0m\u001b[91m \u001b[0m\u001b[1;91mUnrecognized options\u001b[0m\u001b[91m \u001b[0m\u001b[91m─────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[91m─╮\u001b[0m\n",
       "\u001b[91m│\u001b[0m Unrecognized options: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000                                      \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m --Session.signature-scheme=\"hmac-sha256\" --Session.key=b\"07992966-17c4-4623-9c3a-c1536aa9b1db\" --shell=9002     \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m --transport=\"tcp\" --iopub=9004 --f=/root/.local/share/jupyter/runtime/kernel-v2-3168gicBIIWBpmuv.json           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[31m───────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m For full helptext, run \u001b[1mipykernel_launcher.py --help\u001b[0m                                                             \u001b[91m│\u001b[0m\n",
       "\u001b[91m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    }
   ],
   "source": [
    "main(_config.cli())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/.venv/lib/python3.11/site-packages/tyro/_argparse_formatter.py:221\u001b[39m, in \u001b[36mansi_context\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# Use Colorama to support coloring in Windows shells.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcolorama\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# Notes:\u001b[39;00m\n\u001b[32m    224\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    225\u001b[39m     \u001b[38;5;66;03m# (1) This context manager looks very nice and local, but under-the-hood\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    234\u001b[39m     \u001b[38;5;66;03m# are low-effort solutions for either problem, and more modern terminals\u001b[39;00m\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# in Windows (PowerShell, MSYS2, ...) do support ANSI codes anyways.\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'colorama'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mSystemExit\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m main_test(\u001b[43m_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcli\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/src/openpi/training/config.py:645\u001b[39m, in \u001b[36mcli\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    644\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcli\u001b[39m() -> TrainConfig:\n\u001b[32m--> \u001b[39m\u001b[32m645\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtyro\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m.\u001b[49m\u001b[43moverridable_config_cli\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_CONFIGS_DICT\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/.venv/lib/python3.11/site-packages/tyro/extras/_base_configs.py:90\u001b[39m, in \u001b[36moverridable_config_cli\u001b[39m\u001b[34m(configs, prog, description, args, use_underscores, console_outputs, config, sort_subcommands, registry)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyro\u001b[39;00m\n\u001b[32m     89\u001b[39m keys = \u001b[38;5;28mlist\u001b[39m(configs.keys())\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtyro\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcli\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtyro\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubcommand_type_from_defaults\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdescriptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort_subcommands\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort_subcommands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprog\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_underscores\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_underscores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconsole_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconsole_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Don't create subcommands for union types within the config object.\u001b[39;49;00m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyro\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAvoidSubcommands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mregistry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregistry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/.venv/lib/python3.11/site-packages/tyro/_cli.py:205\u001b[39m, in \u001b[36mcli\u001b[39m\u001b[34m(f, prog, description, args, default, return_unknown_args, use_underscores, console_outputs, config, registry, **deprecated_kwargs)\u001b[39m\n\u001b[32m    202\u001b[39m _unsafe_cache.clear_cache()\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _strings.delimeter_context(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_underscores \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m     output = \u001b[43m_cli_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprog\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_unknown_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_unknown_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_underscores\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_underscores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconsole_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconsole_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregistry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregistry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdeprecated_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[38;5;66;03m# Prevent unnecessary memory usage.\u001b[39;00m\n\u001b[32m    221\u001b[39m _unsafe_cache.clear_cache()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/.venv/lib/python3.11/site-packages/tyro/_cli.py:515\u001b[39m, in \u001b[36m_cli_impl\u001b[39m\u001b[34m(f, prog, description, args, default, return_parser, return_unknown_args, console_outputs, config, registry, **deprecated_kwargs)\u001b[39m\n\u001b[32m    513\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    514\u001b[39m         unknown_args = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m         namespace = \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    516\u001b[39m     value_from_prefixed_field_name = \u001b[38;5;28mvars\u001b[39m(namespace)\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dummy_wrapped:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/.venv/lib/python3.11/site-packages/tyro/_argparse.py:1903\u001b[39m, in \u001b[36mArgumentParser.parse_args\u001b[39m\u001b[34m(self, args, namespace)\u001b[39m\n\u001b[32m   1902\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse_args\u001b[39m(\u001b[38;5;28mself\u001b[39m, args=\u001b[38;5;28;01mNone\u001b[39;00m, namespace=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m1903\u001b[39m     args, argv = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_known_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1904\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m argv:\n\u001b[32m   1905\u001b[39m         msg = _(\u001b[33m'\u001b[39m\u001b[33munrecognized arguments: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/.venv/lib/python3.11/site-packages/tyro/_argparse.py:1936\u001b[39m, in \u001b[36mArgumentParser.parse_known_args\u001b[39m\u001b[34m(self, args, namespace)\u001b[39m\n\u001b[32m   1934\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.exit_on_error:\n\u001b[32m   1935\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1936\u001b[39m         namespace, args = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_known_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1937\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ArgumentError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   1938\u001b[39m         \u001b[38;5;28mself\u001b[39m.error(\u001b[38;5;28mstr\u001b[39m(err))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/.venv/lib/python3.11/site-packages/tyro/_argparse_formatter.py:575\u001b[39m, in \u001b[36mTyroArgumentParser._parse_known_args\u001b[39m\u001b[34m(self, arg_strings, namespace)\u001b[39m\n\u001b[32m    568\u001b[39m                 \u001b[38;5;28msetattr\u001b[39m(\n\u001b[32m    569\u001b[39m                     namespace,\n\u001b[32m    570\u001b[39m                     action.dest,\n\u001b[32m    571\u001b[39m                     \u001b[38;5;28mself\u001b[39m._get_value(action, action.default),\n\u001b[32m    572\u001b[39m                 )\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m required_actions:\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthe following arguments are required: \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[43m        \u001b[49m\u001b[43m%\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequired_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[38;5;66;03m# make sure all required groups had one option present\u001b[39;00m\n\u001b[32m    581\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mutually_exclusive_groups:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/.venv/lib/python3.11/site-packages/tyro/_argparse_formatter.py:893\u001b[39m, in \u001b[36mTyroArgumentParser.error\u001b[39m\u001b[34m(self, message)\u001b[39m\n\u001b[32m    874\u001b[39m     console = Console(theme=THEME.as_rich_theme(), stderr=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    875\u001b[39m     console.print(\n\u001b[32m    876\u001b[39m         Panel(\n\u001b[32m    877\u001b[39m             Group(\n\u001b[32m   (...)\u001b[39m\u001b[32m    891\u001b[39m         )\n\u001b[32m    892\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m893\u001b[39m sys.exit(\u001b[32m2\u001b[39m)\n",
      "\u001b[31mSystemExit\u001b[39m: 2"
     ]
    }
   ],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
