{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This jupyter notebook covers the following contents:\n",
    "1. Default configuration in LIBERO\n",
    "2. Basic information about available LIBERO benchmarks\n",
    "   - Get a dictionary of mapping from benchmark name to benchmark class\n",
    "   - Check the integrity of benchmarks\n",
    "   - Check the integrity of init files\n",
    "   - Visualize all the init states of a task\n",
    "   - Download datasets\n",
    "   - Get information about a demonstration file and replay a trajectory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/libero/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from libero.libero import benchmark, get_libero_path, set_libero_default_path\n",
    "import os\n",
    "from termcolor import colored"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Default file paths"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the paths are retrieved from a yaml config file located at `~/.libero/config.yaml`. And the default paths are set to relative to the libero codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning]: datasets path /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/../datasets does not exist!\n",
      "[Warning]: datasets path /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/../datasets does not exist!\n",
      "[Warning]: datasets path /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/../datasets does not exist!\n",
      "[Warning]: datasets path /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/../datasets does not exist!\n",
      "Default benchmark root path:  /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero\n",
      "Default dataset root path:  /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/../datasets\n",
      "Default bddl files root path:  /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/./bddl_files\n"
     ]
    }
   ],
   "source": [
    "benchmark_root_path = get_libero_path(\"benchmark_root\")\n",
    "init_states_default_path = get_libero_path(\"init_states\")\n",
    "datasets_default_path = get_libero_path(\"datasets\")\n",
    "bddl_files_default_path = get_libero_path(\"bddl_files\")\n",
    "print(\"Default benchmark root path: \", benchmark_root_path)\n",
    "print(\"Default dataset root path: \", datasets_default_path)\n",
    "print(\"Default bddl files root path: \", bddl_files_default_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if you want to point your codebase to custom path, you can use `set_libero_path` function to do that. Notice that all the paths change according to `benchmark_root` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] You are changing the default path for Libero config. This will affect all the paths in the config file.\n",
      "[Warning]: assets path /root/custom_project/./assets does not exist!\n",
      "[Warning]: bddl_files path /root/custom_project/./bddl_files does not exist!\n",
      "[Warning]: benchmark_root path /root/custom_project does not exist!\n",
      "[Warning]: datasets path /root/custom_project/../datasets does not exist!\n",
      "[Warning]: init_states path /root/custom_project/./init_files does not exist!\n",
      "[Warning]: assets path /root/custom_project/./assets does not exist!\n",
      "[Warning]: bddl_files path /root/custom_project/./bddl_files does not exist!\n",
      "[Warning]: benchmark_root path /root/custom_project does not exist!\n",
      "[Warning]: datasets path /root/custom_project/../datasets does not exist!\n",
      "[Warning]: init_states path /root/custom_project/./init_files does not exist!\n",
      "[Warning]: assets path /root/custom_project/./assets does not exist!\n",
      "[Warning]: bddl_files path /root/custom_project/./bddl_files does not exist!\n",
      "[Warning]: benchmark_root path /root/custom_project does not exist!\n",
      "[Warning]: datasets path /root/custom_project/../datasets does not exist!\n",
      "[Warning]: init_states path /root/custom_project/./init_files does not exist!\n",
      "[Warning]: assets path /root/custom_project/./assets does not exist!\n",
      "[Warning]: bddl_files path /root/custom_project/./bddl_files does not exist!\n",
      "[Warning]: benchmark_root path /root/custom_project does not exist!\n",
      "[Warning]: datasets path /root/custom_project/../datasets does not exist!\n",
      "[Warning]: init_states path /root/custom_project/./init_files does not exist!\n",
      "Default benchmark root path:  /root/custom_project\n",
      "Default dataset root path:  /root/custom_project/../datasets\n",
      "Default bddl files root path:  /root/custom_project/./bddl_files\n",
      "[Warning] You are changing the default path for Libero config. This will affect all the paths in the config file.\n",
      "[Warning]: datasets path /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/../datasets does not exist!\n",
      "[Warning]: datasets path /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/../datasets does not exist!\n",
      "[Warning]: datasets path /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/../datasets does not exist!\n",
      "[Warning]: datasets path /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/../datasets does not exist!\n",
      "Default benchmark root path:  /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero\n",
      "Default dataset root path:  /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/../datasets\n",
      "Default bddl files root path:  /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/./bddl_files\n"
     ]
    }
   ],
   "source": [
    "set_libero_default_path(os.path.join(os.path.expanduser(\"~\"), \"custom_project\"))\n",
    "benchmark_root_path = get_libero_path(\"benchmark_root\")\n",
    "init_states_default_path = get_libero_path(\"init_states\")\n",
    "datasets_default_path = get_libero_path(\"datasets\")\n",
    "bddl_files_default_path = get_libero_path(\"bddl_files\")\n",
    "print(\"Default benchmark root path: \", benchmark_root_path)\n",
    "print(\"Default dataset root path: \", datasets_default_path)\n",
    "print(\"Default bddl files root path: \", bddl_files_default_path)\n",
    "\n",
    "# If nothing is specified in the `set_libero_default_path` function, the path will be changed back to the default path\n",
    "# We will set back the path to the default path for the subsequent examples\n",
    "set_libero_default_path()\n",
    "benchmark_root_path = get_libero_path(\"benchmark_root\")\n",
    "init_states_default_path = get_libero_path(\"init_states\")\n",
    "datasets_default_path = get_libero_path(\"datasets\")\n",
    "bddl_files_default_path = get_libero_path(\"bddl_files\")\n",
    "print(\"Default benchmark root path: \", benchmark_root_path)\n",
    "print(\"Default dataset root path: \", datasets_default_path)\n",
    "print(\"Default bddl files root path: \", bddl_files_default_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. See available benchmarks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Get a dictionary of mapping from benchmark name to benchmark class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'libero_spatial': <class 'libero.libero.benchmark.LIBERO_SPATIAL'>, 'libero_object': <class 'libero.libero.benchmark.LIBERO_OBJECT'>, 'libero_goal': <class 'libero.libero.benchmark.LIBERO_GOAL'>, 'libero_90': <class 'libero.libero.benchmark.LIBERO_90'>, 'libero_10': <class 'libero.libero.benchmark.LIBERO_10'>, 'libero_100': <class 'libero.libero.benchmark.LIBERO_100'>}\n"
     ]
    }
   ],
   "source": [
    "benchmark_dict = benchmark.get_benchmark_dict()\n",
    "print(benchmark_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Check the integrity of benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "10 tasks in the benchmark libero_10: \n",
      "The benchmark contains the following tasks:\n",
      "\t LIVING_ROOM_SCENE2_put_both_the_alphabet_soup_and_the_tomato_sauce_in_the_basket, detail definition stored in /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/./bddl_files/libero_10/LIVING_ROOM_SCENE2_put_both_the_alphabet_soup_and_the_tomato_sauce_in_the_basket.bddl\n",
      "\t LIVING_ROOM_SCENE2_put_both_the_cream_cheese_box_and_the_butter_in_the_basket, detail definition stored in /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/./bddl_files/libero_10/LIVING_ROOM_SCENE2_put_both_the_cream_cheese_box_and_the_butter_in_the_basket.bddl\n",
      "\t KITCHEN_SCENE3_turn_on_the_stove_and_put_the_moka_pot_on_it, detail definition stored in /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/./bddl_files/libero_10/KITCHEN_SCENE3_turn_on_the_stove_and_put_the_moka_pot_on_it.bddl\n",
      "\t KITCHEN_SCENE4_put_the_black_bowl_in_the_bottom_drawer_of_the_cabinet_and_close_it, detail definition stored in /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/./bddl_files/libero_10/KITCHEN_SCENE4_put_the_black_bowl_in_the_bottom_drawer_of_the_cabinet_and_close_it.bddl\n",
      "\t LIVING_ROOM_SCENE5_put_the_white_mug_on_the_left_plate_and_put_the_yellow_and_white_mug_on_the_right_plate, detail definition stored in /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/./bddl_files/libero_10/LIVING_ROOM_SCENE5_put_the_white_mug_on_the_left_plate_and_put_the_yellow_and_white_mug_on_the_right_plate.bddl\n",
      "\t STUDY_SCENE1_pick_up_the_book_and_place_it_in_the_back_compartment_of_the_caddy, detail definition stored in /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/./bddl_files/libero_10/STUDY_SCENE1_pick_up_the_book_and_place_it_in_the_back_compartment_of_the_caddy.bddl\n",
      "\t LIVING_ROOM_SCENE6_put_the_white_mug_on_the_plate_and_put_the_chocolate_pudding_to_the_right_of_the_plate, detail definition stored in /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/./bddl_files/libero_10/LIVING_ROOM_SCENE6_put_the_white_mug_on_the_plate_and_put_the_chocolate_pudding_to_the_right_of_the_plate.bddl\n",
      "\t LIVING_ROOM_SCENE1_put_both_the_alphabet_soup_and_the_cream_cheese_box_in_the_basket, detail definition stored in /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/./bddl_files/libero_10/LIVING_ROOM_SCENE1_put_both_the_alphabet_soup_and_the_cream_cheese_box_in_the_basket.bddl\n",
      "\t KITCHEN_SCENE8_put_both_moka_pots_on_the_stove, detail definition stored in /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/./bddl_files/libero_10/KITCHEN_SCENE8_put_both_moka_pots_on_the_stove.bddl\n",
      "\t KITCHEN_SCENE6_put_the_yellow_and_white_mug_in_the_microwave_and_close_it, detail definition stored in /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/./bddl_files/libero_10/KITCHEN_SCENE6_put_the_yellow_and_white_mug_in_the_microwave_and_close_it.bddl\n"
     ]
    }
   ],
   "source": [
    "# initialize a benchmark\n",
    "benchmark_instance = benchmark_dict[\"libero_10\"]()\n",
    "num_tasks = benchmark_instance.get_num_tasks()\n",
    "# see how many tasks involved in the benchmark\n",
    "print(f\"{num_tasks} tasks in the benchmark {benchmark_instance.name}: \")\n",
    "\n",
    "# Check if all the task names and their bddl file names\n",
    "task_names = benchmark_instance.get_task_names()\n",
    "print(\"The benchmark contains the following tasks:\")\n",
    "for i in range(num_tasks):\n",
    "    task_name = task_names[i]\n",
    "    task = benchmark_instance.get_task(i)\n",
    "    bddl_file = os.path.join(bddl_files_default_path, task.problem_folder, task.bddl_file)\n",
    "    print(f\"\\t {task_name}, detail definition stored in {bddl_file}\")\n",
    "    if not os.path.exists(bddl_file):\n",
    "        print(colored(f\"[error] bddl file {bddl_file} cannot be found. Check your paths\", \"red\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Check the integrity of init files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The benchmark contains the following tasks:\n",
      "An example of init file is named like this: KITCHEN_SCENE6_put_the_yellow_and_white_mug_in_the_microwave_and_close_it.pruned_init\n",
      "[Warning]: datasets path /inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/../datasets does not exist!\n",
      "(50, 123)\n"
     ]
    }
   ],
   "source": [
    "# Check if all the init states files exist for tasks\n",
    "task_names = benchmark_instance.get_task_names()\n",
    "print(\"The benchmark contains the following tasks:\")\n",
    "for i in range(num_tasks):\n",
    "    task_name = task_names[i]\n",
    "    task = benchmark_instance.get_task(i)\n",
    "    init_states_path = os.path.join(init_states_default_path, task.problem_folder, task.init_states_file)\n",
    "    if not os.path.exists(init_states_path):\n",
    "        print(colored(f\"[error] the init states {init_states_path} cannot be found. Check your paths\", \"red\"))\n",
    "print(f\"An example of init file is named like this: {task.init_states_file}\")\n",
    "\n",
    "# Load torch init files\n",
    "init_states = benchmark_instance.get_task_init_states(0)\n",
    "# Init states in the same (num_init_rollouts, num_simulation_states)\n",
    "print(init_states.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Visualize all the init states of a task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (__init__.py:7)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (__init__.py:8)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /opt/conda/envs/libero/lib/python3.8/site-packages/robosuite/scripts/setup_macros.py (__init__.py:9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Cannot initialize a EGL device display. This likely means that your EGL driver does not support the PLATFORM_DEVICE extension, which is required for creating a headless rendering context.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/notebooks/quick_walkthrough.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://notebook-inspire.sii.edu.cn/inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/notebooks/quick_walkthrough.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mlibero\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlibero\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menvs\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m OffScreenRenderEnv\n\u001b[1;32m      <a href='vscode-notebook-cell://notebook-inspire.sii.edu.cn/inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/notebooks/quick_walkthrough.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m display\n\u001b[1;32m      <a href='vscode-notebook-cell://notebook-inspire.sii.edu.cn/inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/notebooks/quick_walkthrough.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mPIL\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m Image\n",
      "File \u001b[0;32m/inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/envs/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39mbddl_base_domain\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m TASK_MAPPING\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39mbase_object\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m OBJECTS_DICT\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39mproblems\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m/inspire/hdd/global_user/gongjingjing-25039/ytchen/openpi/third_party/libero/libero/libero/envs/bddl_base_domain.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mnumpy\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mrobosuite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransform_utils\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mT\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcopy\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m deepcopy\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mrobosuite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menvironments\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmanipulation\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msingle_arm_env\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m SingleArmEnv\n",
      "File \u001b[0;32m/opt/conda/envs/libero/lib/python3.8/site-packages/robosuite/__init__.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m     ROBOSUITE_DEFAULT_LOGGER\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mIt is recommended to use a private macro file\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m     ROBOSUITE_DEFAULT_LOGGER\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mTo setup, run: python \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/scripts/setup_macros.py\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(robosuite\u001b[39m.\u001b[39m__path__[\u001b[39m0\u001b[39m]))\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mrobosuite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menvironments\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m make\n\u001b[1;32m     13\u001b[0m \u001b[39m# Manipulation environments\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mrobosuite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menvironments\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmanipulation\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlift\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m Lift\n",
      "File \u001b[0;32m/opt/conda/envs/libero/lib/python3.8/site-packages/robosuite/environments/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m REGISTERED_ENVS, MujocoEnv\n\u001b[1;32m      3\u001b[0m ALL_ENVIRONMENTS \u001b[39m=\u001b[39m REGISTERED_ENVS\u001b[39m.\u001b[39mkeys()\n",
      "File \u001b[0;32m/opt/conda/envs/libero/lib/python3.8/site-packages/robosuite/environments/base.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mrobosuite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrenderers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m load_renderer_config\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mrobosuite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m OpenCVRenderer, SimulationError, XMLError\n\u001b[0;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mrobosuite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbinding_utils\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m MjRenderContextOffscreen, MjSim\n\u001b[1;32m     14\u001b[0m REGISTERED_ENVS \u001b[39m=\u001b[39m {}\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mregister_env\u001b[39m(target_class):\n",
      "File \u001b[0;32m/opt/conda/envs/libero/lib/python3.8/site-packages/robosuite/utils/binding_utils.py:58\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mrobosuite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrenderers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontext\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mosmesa_context\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m OSMesaGLContext \u001b[39mas\u001b[39;00m GLContext\n\u001b[1;32m     57\u001b[0m \u001b[39melif\u001b[39;00m _SYSTEM \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mLinux\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m _MUJOCO_GL \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39megl\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 58\u001b[0m     \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mrobosuite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrenderers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontext\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39megl_context\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m EGLGLContext \u001b[39mas\u001b[39;00m GLContext\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mrobosuite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrenderers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontext\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mglfw_context\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m GLFWGLContext \u001b[39mas\u001b[39;00m GLContext\n",
      "File \u001b[0;32m/opt/conda/envs/libero/lib/python3.8/site-packages/robosuite/renderers/context/egl_context.py:32\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39melif\u001b[39;00m PYOPENGL_PLATFORM\u001b[39m.\u001b[39mlower() \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39megl\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     26\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m     27\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot use EGL rendering platform. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe PYOPENGL_PLATFORM environment variable is set to \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(should be either unset or \u001b[39m\u001b[39m'\u001b[39m\u001b[39megl\u001b[39m\u001b[39m'\u001b[39m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m     )\n\u001b[0;32m---> 32\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mmujoco\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39megl\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m egl_ext \u001b[39mas\u001b[39;00m EGL\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mOpenGL\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m error\n\u001b[1;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcreate_initialized_egl_device_display\u001b[39m(device_id\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/envs/libero/lib/python3.8/site-packages/mujoco/egl/__init__.py:67\u001b[0m\n\u001b[1;32m     65\u001b[0m EGL_DISPLAY \u001b[39m=\u001b[39m create_initialized_egl_device_display()\n\u001b[1;32m     66\u001b[0m \u001b[39mif\u001b[39;00m EGL_DISPLAY \u001b[39m==\u001b[39m EGL\u001b[39m.\u001b[39mEGL_NO_DISPLAY:\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m     68\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mCannot initialize a EGL device display. This likely means that your EGL \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     69\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mdriver does not support the PLATFORM_DEVICE extension, which is \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     70\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mrequired for creating a headless rendering context.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     71\u001b[0m atexit\u001b[39m.\u001b[39mregister(EGL\u001b[39m.\u001b[39meglTerminate, EGL_DISPLAY)\n\u001b[1;32m     74\u001b[0m EGL_ATTRIBUTES \u001b[39m=\u001b[39m (\n\u001b[1;32m     75\u001b[0m     EGL\u001b[39m.\u001b[39mEGL_RED_SIZE, \u001b[39m8\u001b[39m,\n\u001b[1;32m     76\u001b[0m     EGL\u001b[39m.\u001b[39mEGL_GREEN_SIZE, \u001b[39m8\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m     EGL\u001b[39m.\u001b[39mEGL_NONE\n\u001b[1;32m     85\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: Cannot initialize a EGL device display. This likely means that your EGL driver does not support the PLATFORM_DEVICE extension, which is required for creating a headless rendering context."
     ]
    }
   ],
   "source": [
    "from libero.libero.envs import OffScreenRenderEnv\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# task_id is the (task_id + 1)th task in the benchmark\n",
    "task_id = 9\n",
    "task = benchmark_instance.get_task(task_id)\n",
    "\n",
    "env_args = {\n",
    "    \"bddl_file_name\": os.path.join(bddl_files_default_path, task.problem_folder, task.bddl_file),\n",
    "    \"camera_heights\": 128,\n",
    "    \"camera_widths\": 128\n",
    "}\n",
    "\n",
    "env = OffScreenRenderEnv(**env_args)\n",
    "\n",
    "\n",
    "init_states = benchmark_instance.get_task_init_states(task_id)\n",
    "\n",
    "# Fix random seeds for reproducibility\n",
    "env.seed(0)\n",
    "\n",
    "def make_grid(images, nrow=8, padding=2, normalize=False, pad_value=0):\n",
    "    \"\"\"Make a grid of images. Make sure images is a 4D tensor in the shape of (B x C x H x W)) or a list of torch tensors.\"\"\"\n",
    "    grid_image = torchvision.utils.make_grid(images, nrow=nrow, padding=padding, normalize=normalize, pad_value=pad_value).permute(1, 2, 0)\n",
    "    return grid_image\n",
    "\n",
    "images = []\n",
    "env.reset()\n",
    "for eval_index in range(len(init_states)):\n",
    "    env.set_init_state(init_states[eval_index])\n",
    "\n",
    "    for _ in range(5):\n",
    "        obs, _, _, _ = env.step([0.] * 7)\n",
    "    images.append(torch.from_numpy(obs[\"agentview_image\"]).permute(2, 0, 1))\n",
    "\n",
    "# # images = torch.stack(images, dim=0).permute(0, 3, 1, 2)\n",
    "# print(images.shape)\n",
    "grid_image = make_grid(images, nrow=10, padding=2, pad_value=0)\n",
    "display(Image.fromarray(grid_image.numpy()[::-1]))\n",
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Download datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ ] Dataset libero_object not found!!!\n",
      "[ ] Dataset libero_goal not found!!!\n",
      "[X] Dataset libero_spatial is complete\n",
      "[X] Dataset libero_10 is complete\n",
      "[X] Dataset libero_90 is complete\n",
      "Downloading libero_spatial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04k94hyizn4huhbv5sz4ev9p2h1p6s7f.zip: 2.88GB [02:56, 16.3MB/s]                            \n"
     ]
    }
   ],
   "source": [
    "import libero.libero.utils.download_utils as download_utils\n",
    "\n",
    "download_dir = get_libero_path(\"datasets\")\n",
    "datasets = \"libero_spatial\" # Can specify \"all\", \"libero_goal\", \"libero_spatial\", \"libero_object\", \"libero_100\"\n",
    "\n",
    "libero_datasets_exist = download_utils.check_libero_dataset(download_dir=download_dir)\n",
    "\n",
    "if not libero_datasets_exist:\n",
    "    download_utils.libero_dataset_download(download_dir=download_dir, datasets=datasets)\n",
    "\n",
    "# Check if the demo files exist\n",
    "demo_files = [os.path.join(datasets_default_path, benchmark_instance.get_task_demonstration(i)) for i in range(num_tasks)]\n",
    "for demo_file in demo_files:\n",
    "    if not os.path.exists(demo_file):\n",
    "        print(colored(f\"[error] demo file {demo_file} cannot be found. Check your paths\", \"red\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Get information about a demonstration file and replay a trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total transitions: 15232\n",
      "total trajectories: 50\n",
      "traj length mean: 304.64\n",
      "traj length std: 46.59989699559432\n",
      "traj length min: 224\n",
      "traj length max: 449\n",
      "action min: -1.0\n",
      "action max: 1.0\n",
      "language instruction: put the yellow and white mug in the microwave and close it\n",
      "\n",
      "==== Filter Keys ====\n",
      "no filter keys\n",
      "\n",
      "\n",
      "==== Env Meta ====\n",
      "{\n",
      "    \"type\": 1,\n",
      "    \"env_name\": \"Libero_Kitchen_Tabletop_Manipulation\",\n",
      "    \"problem_name\": \"libero_kitchen_tabletop_manipulation\",\n",
      "    \"bddl_file\": \"chiliocosm/bddl_files/libero_100/KITCHEN_SCENE6_put_the_yellow_and_white_mug_in_the_microwave_and_close_it.bddl\",\n",
      "    \"env_kwargs\": {\n",
      "        \"robots\": [\n",
      "            \"Panda\"\n",
      "        ],\n",
      "        \"controller_configs\": {\n",
      "            \"type\": \"OSC_POSE\",\n",
      "            \"input_max\": 1,\n",
      "            \"input_min\": -1,\n",
      "            \"output_max\": [\n",
      "                0.05,\n",
      "                0.05,\n",
      "                0.05,\n",
      "                0.5,\n",
      "                0.5,\n",
      "                0.5\n",
      "            ],\n",
      "            \"output_min\": [\n",
      "                -0.05,\n",
      "                -0.05,\n",
      "                -0.05,\n",
      "                -0.5,\n",
      "                -0.5,\n",
      "                -0.5\n",
      "            ],\n",
      "            \"kp\": 150,\n",
      "            \"damping_ratio\": 1,\n",
      "            \"impedance_mode\": \"fixed\",\n",
      "            \"kp_limits\": [\n",
      "                0,\n",
      "                300\n",
      "            ],\n",
      "            \"damping_ratio_limits\": [\n",
      "                0,\n",
      "                10\n",
      "            ],\n",
      "            \"position_limits\": null,\n",
      "            \"orientation_limits\": null,\n",
      "            \"uncouple_pos_ori\": true,\n",
      "            \"control_delta\": true,\n",
      "            \"interpolation\": null,\n",
      "            \"ramp_ratio\": 0.2\n",
      "        },\n",
      "        \"bddl_file_name\": \"chiliocosm/bddl_files/libero_100/KITCHEN_SCENE6_put_the_yellow_and_white_mug_in_the_microwave_and_close_it.bddl\",\n",
      "        \"has_renderer\": false,\n",
      "        \"has_offscreen_renderer\": true,\n",
      "        \"ignore_done\": true,\n",
      "        \"use_camera_obs\": true,\n",
      "        \"camera_depths\": false,\n",
      "        \"camera_names\": [\n",
      "            \"robot0_eye_in_hand\",\n",
      "            \"agentview\"\n",
      "        ],\n",
      "        \"reward_shaping\": true,\n",
      "        \"control_freq\": 20,\n",
      "        \"camera_heights\": 128,\n",
      "        \"camera_widths\": 128,\n",
      "        \"camera_segmentations\": null\n",
      "    }\n",
      "}\n",
      "\n",
      "==== Dataset Structure ====\n",
      "episode demo_0 with 329 transitions\n",
      "    key: actions with shape (329, 7)\n",
      "    key: dones with shape (329,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (329, 128, 128, 3)\n",
      "        observation key ee_ori with shape (329, 3)\n",
      "        observation key ee_pos with shape (329, 3)\n",
      "        observation key ee_states with shape (329, 6)\n",
      "        observation key eye_in_hand_rgb with shape (329, 128, 128, 3)\n",
      "        observation key gripper_states with shape (329, 2)\n",
      "        observation key joint_states with shape (329, 7)\n",
      "    key: rewards with shape (329,)\n",
      "    key: robot_states with shape (329, 9)\n",
      "    key: states with shape (329, 47)\n",
      "episode demo_1 with 248 transitions\n",
      "    key: actions with shape (248, 7)\n",
      "    key: dones with shape (248,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (248, 128, 128, 3)\n",
      "        observation key ee_ori with shape (248, 3)\n",
      "        observation key ee_pos with shape (248, 3)\n",
      "        observation key ee_states with shape (248, 6)\n",
      "        observation key eye_in_hand_rgb with shape (248, 128, 128, 3)\n",
      "        observation key gripper_states with shape (248, 2)\n",
      "        observation key joint_states with shape (248, 7)\n",
      "    key: rewards with shape (248,)\n",
      "    key: robot_states with shape (248, 9)\n",
      "    key: states with shape (248, 47)\n",
      "episode demo_2 with 271 transitions\n",
      "    key: actions with shape (271, 7)\n",
      "    key: dones with shape (271,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (271, 128, 128, 3)\n",
      "        observation key ee_ori with shape (271, 3)\n",
      "        observation key ee_pos with shape (271, 3)\n",
      "        observation key ee_states with shape (271, 6)\n",
      "        observation key eye_in_hand_rgb with shape (271, 128, 128, 3)\n",
      "        observation key gripper_states with shape (271, 2)\n",
      "        observation key joint_states with shape (271, 7)\n",
      "    key: rewards with shape (271,)\n",
      "    key: robot_states with shape (271, 9)\n",
      "    key: states with shape (271, 47)\n",
      "episode demo_3 with 415 transitions\n",
      "    key: actions with shape (415, 7)\n",
      "    key: dones with shape (415,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (415, 128, 128, 3)\n",
      "        observation key ee_ori with shape (415, 3)\n",
      "        observation key ee_pos with shape (415, 3)\n",
      "        observation key ee_states with shape (415, 6)\n",
      "        observation key eye_in_hand_rgb with shape (415, 128, 128, 3)\n",
      "        observation key gripper_states with shape (415, 2)\n",
      "        observation key joint_states with shape (415, 7)\n",
      "    key: rewards with shape (415,)\n",
      "    key: robot_states with shape (415, 9)\n",
      "    key: states with shape (415, 47)\n",
      "episode demo_4 with 364 transitions\n",
      "    key: actions with shape (364, 7)\n",
      "    key: dones with shape (364,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (364, 128, 128, 3)\n",
      "        observation key ee_ori with shape (364, 3)\n",
      "        observation key ee_pos with shape (364, 3)\n",
      "        observation key ee_states with shape (364, 6)\n",
      "        observation key eye_in_hand_rgb with shape (364, 128, 128, 3)\n",
      "        observation key gripper_states with shape (364, 2)\n",
      "        observation key joint_states with shape (364, 7)\n",
      "    key: rewards with shape (364,)\n",
      "    key: robot_states with shape (364, 9)\n",
      "    key: states with shape (364, 47)\n",
      "episode demo_5 with 293 transitions\n",
      "    key: actions with shape (293, 7)\n",
      "    key: dones with shape (293,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (293, 128, 128, 3)\n",
      "        observation key ee_ori with shape (293, 3)\n",
      "        observation key ee_pos with shape (293, 3)\n",
      "        observation key ee_states with shape (293, 6)\n",
      "        observation key eye_in_hand_rgb with shape (293, 128, 128, 3)\n",
      "        observation key gripper_states with shape (293, 2)\n",
      "        observation key joint_states with shape (293, 7)\n",
      "    key: rewards with shape (293,)\n",
      "    key: robot_states with shape (293, 9)\n",
      "    key: states with shape (293, 47)\n",
      "episode demo_6 with 317 transitions\n",
      "    key: actions with shape (317, 7)\n",
      "    key: dones with shape (317,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (317, 128, 128, 3)\n",
      "        observation key ee_ori with shape (317, 3)\n",
      "        observation key ee_pos with shape (317, 3)\n",
      "        observation key ee_states with shape (317, 6)\n",
      "        observation key eye_in_hand_rgb with shape (317, 128, 128, 3)\n",
      "        observation key gripper_states with shape (317, 2)\n",
      "        observation key joint_states with shape (317, 7)\n",
      "    key: rewards with shape (317,)\n",
      "    key: robot_states with shape (317, 9)\n",
      "    key: states with shape (317, 47)\n",
      "episode demo_7 with 307 transitions\n",
      "    key: actions with shape (307, 7)\n",
      "    key: dones with shape (307,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (307, 128, 128, 3)\n",
      "        observation key ee_ori with shape (307, 3)\n",
      "        observation key ee_pos with shape (307, 3)\n",
      "        observation key ee_states with shape (307, 6)\n",
      "        observation key eye_in_hand_rgb with shape (307, 128, 128, 3)\n",
      "        observation key gripper_states with shape (307, 2)\n",
      "        observation key joint_states with shape (307, 7)\n",
      "    key: rewards with shape (307,)\n",
      "    key: robot_states with shape (307, 9)\n",
      "    key: states with shape (307, 47)\n",
      "episode demo_8 with 317 transitions\n",
      "    key: actions with shape (317, 7)\n",
      "    key: dones with shape (317,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (317, 128, 128, 3)\n",
      "        observation key ee_ori with shape (317, 3)\n",
      "        observation key ee_pos with shape (317, 3)\n",
      "        observation key ee_states with shape (317, 6)\n",
      "        observation key eye_in_hand_rgb with shape (317, 128, 128, 3)\n",
      "        observation key gripper_states with shape (317, 2)\n",
      "        observation key joint_states with shape (317, 7)\n",
      "    key: rewards with shape (317,)\n",
      "    key: robot_states with shape (317, 9)\n",
      "    key: states with shape (317, 47)\n",
      "episode demo_9 with 301 transitions\n",
      "    key: actions with shape (301, 7)\n",
      "    key: dones with shape (301,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (301, 128, 128, 3)\n",
      "        observation key ee_ori with shape (301, 3)\n",
      "        observation key ee_pos with shape (301, 3)\n",
      "        observation key ee_states with shape (301, 6)\n",
      "        observation key eye_in_hand_rgb with shape (301, 128, 128, 3)\n",
      "        observation key gripper_states with shape (301, 2)\n",
      "        observation key joint_states with shape (301, 7)\n",
      "    key: rewards with shape (301,)\n",
      "    key: robot_states with shape (301, 9)\n",
      "    key: states with shape (301, 47)\n",
      "episode demo_10 with 285 transitions\n",
      "    key: actions with shape (285, 7)\n",
      "    key: dones with shape (285,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (285, 128, 128, 3)\n",
      "        observation key ee_ori with shape (285, 3)\n",
      "        observation key ee_pos with shape (285, 3)\n",
      "        observation key ee_states with shape (285, 6)\n",
      "        observation key eye_in_hand_rgb with shape (285, 128, 128, 3)\n",
      "        observation key gripper_states with shape (285, 2)\n",
      "        observation key joint_states with shape (285, 7)\n",
      "    key: rewards with shape (285,)\n",
      "    key: robot_states with shape (285, 9)\n",
      "    key: states with shape (285, 47)\n",
      "episode demo_11 with 253 transitions\n",
      "    key: actions with shape (253, 7)\n",
      "    key: dones with shape (253,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (253, 128, 128, 3)\n",
      "        observation key ee_ori with shape (253, 3)\n",
      "        observation key ee_pos with shape (253, 3)\n",
      "        observation key ee_states with shape (253, 6)\n",
      "        observation key eye_in_hand_rgb with shape (253, 128, 128, 3)\n",
      "        observation key gripper_states with shape (253, 2)\n",
      "        observation key joint_states with shape (253, 7)\n",
      "    key: rewards with shape (253,)\n",
      "    key: robot_states with shape (253, 9)\n",
      "    key: states with shape (253, 47)\n",
      "episode demo_12 with 334 transitions\n",
      "    key: actions with shape (334, 7)\n",
      "    key: dones with shape (334,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (334, 128, 128, 3)\n",
      "        observation key ee_ori with shape (334, 3)\n",
      "        observation key ee_pos with shape (334, 3)\n",
      "        observation key ee_states with shape (334, 6)\n",
      "        observation key eye_in_hand_rgb with shape (334, 128, 128, 3)\n",
      "        observation key gripper_states with shape (334, 2)\n",
      "        observation key joint_states with shape (334, 7)\n",
      "    key: rewards with shape (334,)\n",
      "    key: robot_states with shape (334, 9)\n",
      "    key: states with shape (334, 47)\n",
      "episode demo_13 with 310 transitions\n",
      "    key: actions with shape (310, 7)\n",
      "    key: dones with shape (310,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (310, 128, 128, 3)\n",
      "        observation key ee_ori with shape (310, 3)\n",
      "        observation key ee_pos with shape (310, 3)\n",
      "        observation key ee_states with shape (310, 6)\n",
      "        observation key eye_in_hand_rgb with shape (310, 128, 128, 3)\n",
      "        observation key gripper_states with shape (310, 2)\n",
      "        observation key joint_states with shape (310, 7)\n",
      "    key: rewards with shape (310,)\n",
      "    key: robot_states with shape (310, 9)\n",
      "    key: states with shape (310, 47)\n",
      "episode demo_14 with 329 transitions\n",
      "    key: actions with shape (329, 7)\n",
      "    key: dones with shape (329,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (329, 128, 128, 3)\n",
      "        observation key ee_ori with shape (329, 3)\n",
      "        observation key ee_pos with shape (329, 3)\n",
      "        observation key ee_states with shape (329, 6)\n",
      "        observation key eye_in_hand_rgb with shape (329, 128, 128, 3)\n",
      "        observation key gripper_states with shape (329, 2)\n",
      "        observation key joint_states with shape (329, 7)\n",
      "    key: rewards with shape (329,)\n",
      "    key: robot_states with shape (329, 9)\n",
      "    key: states with shape (329, 47)\n",
      "episode demo_15 with 316 transitions\n",
      "    key: actions with shape (316, 7)\n",
      "    key: dones with shape (316,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (316, 128, 128, 3)\n",
      "        observation key ee_ori with shape (316, 3)\n",
      "        observation key ee_pos with shape (316, 3)\n",
      "        observation key ee_states with shape (316, 6)\n",
      "        observation key eye_in_hand_rgb with shape (316, 128, 128, 3)\n",
      "        observation key gripper_states with shape (316, 2)\n",
      "        observation key joint_states with shape (316, 7)\n",
      "    key: rewards with shape (316,)\n",
      "    key: robot_states with shape (316, 9)\n",
      "    key: states with shape (316, 47)\n",
      "episode demo_16 with 268 transitions\n",
      "    key: actions with shape (268, 7)\n",
      "    key: dones with shape (268,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (268, 128, 128, 3)\n",
      "        observation key ee_ori with shape (268, 3)\n",
      "        observation key ee_pos with shape (268, 3)\n",
      "        observation key ee_states with shape (268, 6)\n",
      "        observation key eye_in_hand_rgb with shape (268, 128, 128, 3)\n",
      "        observation key gripper_states with shape (268, 2)\n",
      "        observation key joint_states with shape (268, 7)\n",
      "    key: rewards with shape (268,)\n",
      "    key: robot_states with shape (268, 9)\n",
      "    key: states with shape (268, 47)\n",
      "episode demo_17 with 279 transitions\n",
      "    key: actions with shape (279, 7)\n",
      "    key: dones with shape (279,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (279, 128, 128, 3)\n",
      "        observation key ee_ori with shape (279, 3)\n",
      "        observation key ee_pos with shape (279, 3)\n",
      "        observation key ee_states with shape (279, 6)\n",
      "        observation key eye_in_hand_rgb with shape (279, 128, 128, 3)\n",
      "        observation key gripper_states with shape (279, 2)\n",
      "        observation key joint_states with shape (279, 7)\n",
      "    key: rewards with shape (279,)\n",
      "    key: robot_states with shape (279, 9)\n",
      "    key: states with shape (279, 47)\n",
      "episode demo_18 with 260 transitions\n",
      "    key: actions with shape (260, 7)\n",
      "    key: dones with shape (260,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (260, 128, 128, 3)\n",
      "        observation key ee_ori with shape (260, 3)\n",
      "        observation key ee_pos with shape (260, 3)\n",
      "        observation key ee_states with shape (260, 6)\n",
      "        observation key eye_in_hand_rgb with shape (260, 128, 128, 3)\n",
      "        observation key gripper_states with shape (260, 2)\n",
      "        observation key joint_states with shape (260, 7)\n",
      "    key: rewards with shape (260,)\n",
      "    key: robot_states with shape (260, 9)\n",
      "    key: states with shape (260, 47)\n",
      "episode demo_19 with 317 transitions\n",
      "    key: actions with shape (317, 7)\n",
      "    key: dones with shape (317,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (317, 128, 128, 3)\n",
      "        observation key ee_ori with shape (317, 3)\n",
      "        observation key ee_pos with shape (317, 3)\n",
      "        observation key ee_states with shape (317, 6)\n",
      "        observation key eye_in_hand_rgb with shape (317, 128, 128, 3)\n",
      "        observation key gripper_states with shape (317, 2)\n",
      "        observation key joint_states with shape (317, 7)\n",
      "    key: rewards with shape (317,)\n",
      "    key: robot_states with shape (317, 9)\n",
      "    key: states with shape (317, 47)\n",
      "episode demo_20 with 286 transitions\n",
      "    key: actions with shape (286, 7)\n",
      "    key: dones with shape (286,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (286, 128, 128, 3)\n",
      "        observation key ee_ori with shape (286, 3)\n",
      "        observation key ee_pos with shape (286, 3)\n",
      "        observation key ee_states with shape (286, 6)\n",
      "        observation key eye_in_hand_rgb with shape (286, 128, 128, 3)\n",
      "        observation key gripper_states with shape (286, 2)\n",
      "        observation key joint_states with shape (286, 7)\n",
      "    key: rewards with shape (286,)\n",
      "    key: robot_states with shape (286, 9)\n",
      "    key: states with shape (286, 47)\n",
      "episode demo_21 with 302 transitions\n",
      "    key: actions with shape (302, 7)\n",
      "    key: dones with shape (302,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (302, 128, 128, 3)\n",
      "        observation key ee_ori with shape (302, 3)\n",
      "        observation key ee_pos with shape (302, 3)\n",
      "        observation key ee_states with shape (302, 6)\n",
      "        observation key eye_in_hand_rgb with shape (302, 128, 128, 3)\n",
      "        observation key gripper_states with shape (302, 2)\n",
      "        observation key joint_states with shape (302, 7)\n",
      "    key: rewards with shape (302,)\n",
      "    key: robot_states with shape (302, 9)\n",
      "    key: states with shape (302, 47)\n",
      "episode demo_22 with 306 transitions\n",
      "    key: actions with shape (306, 7)\n",
      "    key: dones with shape (306,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (306, 128, 128, 3)\n",
      "        observation key ee_ori with shape (306, 3)\n",
      "        observation key ee_pos with shape (306, 3)\n",
      "        observation key ee_states with shape (306, 6)\n",
      "        observation key eye_in_hand_rgb with shape (306, 128, 128, 3)\n",
      "        observation key gripper_states with shape (306, 2)\n",
      "        observation key joint_states with shape (306, 7)\n",
      "    key: rewards with shape (306,)\n",
      "    key: robot_states with shape (306, 9)\n",
      "    key: states with shape (306, 47)\n",
      "episode demo_23 with 343 transitions\n",
      "    key: actions with shape (343, 7)\n",
      "    key: dones with shape (343,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (343, 128, 128, 3)\n",
      "        observation key ee_ori with shape (343, 3)\n",
      "        observation key ee_pos with shape (343, 3)\n",
      "        observation key ee_states with shape (343, 6)\n",
      "        observation key eye_in_hand_rgb with shape (343, 128, 128, 3)\n",
      "        observation key gripper_states with shape (343, 2)\n",
      "        observation key joint_states with shape (343, 7)\n",
      "    key: rewards with shape (343,)\n",
      "    key: robot_states with shape (343, 9)\n",
      "    key: states with shape (343, 47)\n",
      "episode demo_24 with 267 transitions\n",
      "    key: actions with shape (267, 7)\n",
      "    key: dones with shape (267,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (267, 128, 128, 3)\n",
      "        observation key ee_ori with shape (267, 3)\n",
      "        observation key ee_pos with shape (267, 3)\n",
      "        observation key ee_states with shape (267, 6)\n",
      "        observation key eye_in_hand_rgb with shape (267, 128, 128, 3)\n",
      "        observation key gripper_states with shape (267, 2)\n",
      "        observation key joint_states with shape (267, 7)\n",
      "    key: rewards with shape (267,)\n",
      "    key: robot_states with shape (267, 9)\n",
      "    key: states with shape (267, 47)\n",
      "episode demo_25 with 255 transitions\n",
      "    key: actions with shape (255, 7)\n",
      "    key: dones with shape (255,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (255, 128, 128, 3)\n",
      "        observation key ee_ori with shape (255, 3)\n",
      "        observation key ee_pos with shape (255, 3)\n",
      "        observation key ee_states with shape (255, 6)\n",
      "        observation key eye_in_hand_rgb with shape (255, 128, 128, 3)\n",
      "        observation key gripper_states with shape (255, 2)\n",
      "        observation key joint_states with shape (255, 7)\n",
      "    key: rewards with shape (255,)\n",
      "    key: robot_states with shape (255, 9)\n",
      "    key: states with shape (255, 47)\n",
      "episode demo_26 with 258 transitions\n",
      "    key: actions with shape (258, 7)\n",
      "    key: dones with shape (258,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (258, 128, 128, 3)\n",
      "        observation key ee_ori with shape (258, 3)\n",
      "        observation key ee_pos with shape (258, 3)\n",
      "        observation key ee_states with shape (258, 6)\n",
      "        observation key eye_in_hand_rgb with shape (258, 128, 128, 3)\n",
      "        observation key gripper_states with shape (258, 2)\n",
      "        observation key joint_states with shape (258, 7)\n",
      "    key: rewards with shape (258,)\n",
      "    key: robot_states with shape (258, 9)\n",
      "    key: states with shape (258, 47)\n",
      "episode demo_27 with 373 transitions\n",
      "    key: actions with shape (373, 7)\n",
      "    key: dones with shape (373,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (373, 128, 128, 3)\n",
      "        observation key ee_ori with shape (373, 3)\n",
      "        observation key ee_pos with shape (373, 3)\n",
      "        observation key ee_states with shape (373, 6)\n",
      "        observation key eye_in_hand_rgb with shape (373, 128, 128, 3)\n",
      "        observation key gripper_states with shape (373, 2)\n",
      "        observation key joint_states with shape (373, 7)\n",
      "    key: rewards with shape (373,)\n",
      "    key: robot_states with shape (373, 9)\n",
      "    key: states with shape (373, 47)\n",
      "episode demo_28 with 239 transitions\n",
      "    key: actions with shape (239, 7)\n",
      "    key: dones with shape (239,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (239, 128, 128, 3)\n",
      "        observation key ee_ori with shape (239, 3)\n",
      "        observation key ee_pos with shape (239, 3)\n",
      "        observation key ee_states with shape (239, 6)\n",
      "        observation key eye_in_hand_rgb with shape (239, 128, 128, 3)\n",
      "        observation key gripper_states with shape (239, 2)\n",
      "        observation key joint_states with shape (239, 7)\n",
      "    key: rewards with shape (239,)\n",
      "    key: robot_states with shape (239, 9)\n",
      "    key: states with shape (239, 47)\n",
      "episode demo_29 with 224 transitions\n",
      "    key: actions with shape (224, 7)\n",
      "    key: dones with shape (224,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (224, 128, 128, 3)\n",
      "        observation key ee_ori with shape (224, 3)\n",
      "        observation key ee_pos with shape (224, 3)\n",
      "        observation key ee_states with shape (224, 6)\n",
      "        observation key eye_in_hand_rgb with shape (224, 128, 128, 3)\n",
      "        observation key gripper_states with shape (224, 2)\n",
      "        observation key joint_states with shape (224, 7)\n",
      "    key: rewards with shape (224,)\n",
      "    key: robot_states with shape (224, 9)\n",
      "    key: states with shape (224, 47)\n",
      "episode demo_30 with 337 transitions\n",
      "    key: actions with shape (337, 7)\n",
      "    key: dones with shape (337,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (337, 128, 128, 3)\n",
      "        observation key ee_ori with shape (337, 3)\n",
      "        observation key ee_pos with shape (337, 3)\n",
      "        observation key ee_states with shape (337, 6)\n",
      "        observation key eye_in_hand_rgb with shape (337, 128, 128, 3)\n",
      "        observation key gripper_states with shape (337, 2)\n",
      "        observation key joint_states with shape (337, 7)\n",
      "    key: rewards with shape (337,)\n",
      "    key: robot_states with shape (337, 9)\n",
      "    key: states with shape (337, 47)\n",
      "episode demo_31 with 291 transitions\n",
      "    key: actions with shape (291, 7)\n",
      "    key: dones with shape (291,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (291, 128, 128, 3)\n",
      "        observation key ee_ori with shape (291, 3)\n",
      "        observation key ee_pos with shape (291, 3)\n",
      "        observation key ee_states with shape (291, 6)\n",
      "        observation key eye_in_hand_rgb with shape (291, 128, 128, 3)\n",
      "        observation key gripper_states with shape (291, 2)\n",
      "        observation key joint_states with shape (291, 7)\n",
      "    key: rewards with shape (291,)\n",
      "    key: robot_states with shape (291, 9)\n",
      "    key: states with shape (291, 47)\n",
      "episode demo_32 with 265 transitions\n",
      "    key: actions with shape (265, 7)\n",
      "    key: dones with shape (265,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (265, 128, 128, 3)\n",
      "        observation key ee_ori with shape (265, 3)\n",
      "        observation key ee_pos with shape (265, 3)\n",
      "        observation key ee_states with shape (265, 6)\n",
      "        observation key eye_in_hand_rgb with shape (265, 128, 128, 3)\n",
      "        observation key gripper_states with shape (265, 2)\n",
      "        observation key joint_states with shape (265, 7)\n",
      "    key: rewards with shape (265,)\n",
      "    key: robot_states with shape (265, 9)\n",
      "    key: states with shape (265, 47)\n",
      "episode demo_33 with 256 transitions\n",
      "    key: actions with shape (256, 7)\n",
      "    key: dones with shape (256,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (256, 128, 128, 3)\n",
      "        observation key ee_ori with shape (256, 3)\n",
      "        observation key ee_pos with shape (256, 3)\n",
      "        observation key ee_states with shape (256, 6)\n",
      "        observation key eye_in_hand_rgb with shape (256, 128, 128, 3)\n",
      "        observation key gripper_states with shape (256, 2)\n",
      "        observation key joint_states with shape (256, 7)\n",
      "    key: rewards with shape (256,)\n",
      "    key: robot_states with shape (256, 9)\n",
      "    key: states with shape (256, 47)\n",
      "episode demo_34 with 395 transitions\n",
      "    key: actions with shape (395, 7)\n",
      "    key: dones with shape (395,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (395, 128, 128, 3)\n",
      "        observation key ee_ori with shape (395, 3)\n",
      "        observation key ee_pos with shape (395, 3)\n",
      "        observation key ee_states with shape (395, 6)\n",
      "        observation key eye_in_hand_rgb with shape (395, 128, 128, 3)\n",
      "        observation key gripper_states with shape (395, 2)\n",
      "        observation key joint_states with shape (395, 7)\n",
      "    key: rewards with shape (395,)\n",
      "    key: robot_states with shape (395, 9)\n",
      "    key: states with shape (395, 47)\n",
      "episode demo_35 with 269 transitions\n",
      "    key: actions with shape (269, 7)\n",
      "    key: dones with shape (269,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (269, 128, 128, 3)\n",
      "        observation key ee_ori with shape (269, 3)\n",
      "        observation key ee_pos with shape (269, 3)\n",
      "        observation key ee_states with shape (269, 6)\n",
      "        observation key eye_in_hand_rgb with shape (269, 128, 128, 3)\n",
      "        observation key gripper_states with shape (269, 2)\n",
      "        observation key joint_states with shape (269, 7)\n",
      "    key: rewards with shape (269,)\n",
      "    key: robot_states with shape (269, 9)\n",
      "    key: states with shape (269, 47)\n",
      "episode demo_36 with 449 transitions\n",
      "    key: actions with shape (449, 7)\n",
      "    key: dones with shape (449,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (449, 128, 128, 3)\n",
      "        observation key ee_ori with shape (449, 3)\n",
      "        observation key ee_pos with shape (449, 3)\n",
      "        observation key ee_states with shape (449, 6)\n",
      "        observation key eye_in_hand_rgb with shape (449, 128, 128, 3)\n",
      "        observation key gripper_states with shape (449, 2)\n",
      "        observation key joint_states with shape (449, 7)\n",
      "    key: rewards with shape (449,)\n",
      "    key: robot_states with shape (449, 9)\n",
      "    key: states with shape (449, 47)\n",
      "episode demo_37 with 278 transitions\n",
      "    key: actions with shape (278, 7)\n",
      "    key: dones with shape (278,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (278, 128, 128, 3)\n",
      "        observation key ee_ori with shape (278, 3)\n",
      "        observation key ee_pos with shape (278, 3)\n",
      "        observation key ee_states with shape (278, 6)\n",
      "        observation key eye_in_hand_rgb with shape (278, 128, 128, 3)\n",
      "        observation key gripper_states with shape (278, 2)\n",
      "        observation key joint_states with shape (278, 7)\n",
      "    key: rewards with shape (278,)\n",
      "    key: robot_states with shape (278, 9)\n",
      "    key: states with shape (278, 47)\n",
      "episode demo_38 with 341 transitions\n",
      "    key: actions with shape (341, 7)\n",
      "    key: dones with shape (341,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (341, 128, 128, 3)\n",
      "        observation key ee_ori with shape (341, 3)\n",
      "        observation key ee_pos with shape (341, 3)\n",
      "        observation key ee_states with shape (341, 6)\n",
      "        observation key eye_in_hand_rgb with shape (341, 128, 128, 3)\n",
      "        observation key gripper_states with shape (341, 2)\n",
      "        observation key joint_states with shape (341, 7)\n",
      "    key: rewards with shape (341,)\n",
      "    key: robot_states with shape (341, 9)\n",
      "    key: states with shape (341, 47)\n",
      "episode demo_39 with 345 transitions\n",
      "    key: actions with shape (345, 7)\n",
      "    key: dones with shape (345,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (345, 128, 128, 3)\n",
      "        observation key ee_ori with shape (345, 3)\n",
      "        observation key ee_pos with shape (345, 3)\n",
      "        observation key ee_states with shape (345, 6)\n",
      "        observation key eye_in_hand_rgb with shape (345, 128, 128, 3)\n",
      "        observation key gripper_states with shape (345, 2)\n",
      "        observation key joint_states with shape (345, 7)\n",
      "    key: rewards with shape (345,)\n",
      "    key: robot_states with shape (345, 9)\n",
      "    key: states with shape (345, 47)\n",
      "episode demo_40 with 342 transitions\n",
      "    key: actions with shape (342, 7)\n",
      "    key: dones with shape (342,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (342, 128, 128, 3)\n",
      "        observation key ee_ori with shape (342, 3)\n",
      "        observation key ee_pos with shape (342, 3)\n",
      "        observation key ee_states with shape (342, 6)\n",
      "        observation key eye_in_hand_rgb with shape (342, 128, 128, 3)\n",
      "        observation key gripper_states with shape (342, 2)\n",
      "        observation key joint_states with shape (342, 7)\n",
      "    key: rewards with shape (342,)\n",
      "    key: robot_states with shape (342, 9)\n",
      "    key: states with shape (342, 47)\n",
      "episode demo_41 with 353 transitions\n",
      "    key: actions with shape (353, 7)\n",
      "    key: dones with shape (353,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (353, 128, 128, 3)\n",
      "        observation key ee_ori with shape (353, 3)\n",
      "        observation key ee_pos with shape (353, 3)\n",
      "        observation key ee_states with shape (353, 6)\n",
      "        observation key eye_in_hand_rgb with shape (353, 128, 128, 3)\n",
      "        observation key gripper_states with shape (353, 2)\n",
      "        observation key joint_states with shape (353, 7)\n",
      "    key: rewards with shape (353,)\n",
      "    key: robot_states with shape (353, 9)\n",
      "    key: states with shape (353, 47)\n",
      "episode demo_42 with 288 transitions\n",
      "    key: actions with shape (288, 7)\n",
      "    key: dones with shape (288,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (288, 128, 128, 3)\n",
      "        observation key ee_ori with shape (288, 3)\n",
      "        observation key ee_pos with shape (288, 3)\n",
      "        observation key ee_states with shape (288, 6)\n",
      "        observation key eye_in_hand_rgb with shape (288, 128, 128, 3)\n",
      "        observation key gripper_states with shape (288, 2)\n",
      "        observation key joint_states with shape (288, 7)\n",
      "    key: rewards with shape (288,)\n",
      "    key: robot_states with shape (288, 9)\n",
      "    key: states with shape (288, 47)\n",
      "episode demo_43 with 316 transitions\n",
      "    key: actions with shape (316, 7)\n",
      "    key: dones with shape (316,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (316, 128, 128, 3)\n",
      "        observation key ee_ori with shape (316, 3)\n",
      "        observation key ee_pos with shape (316, 3)\n",
      "        observation key ee_states with shape (316, 6)\n",
      "        observation key eye_in_hand_rgb with shape (316, 128, 128, 3)\n",
      "        observation key gripper_states with shape (316, 2)\n",
      "        observation key joint_states with shape (316, 7)\n",
      "    key: rewards with shape (316,)\n",
      "    key: robot_states with shape (316, 9)\n",
      "    key: states with shape (316, 47)\n",
      "episode demo_44 with 300 transitions\n",
      "    key: actions with shape (300, 7)\n",
      "    key: dones with shape (300,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (300, 128, 128, 3)\n",
      "        observation key ee_ori with shape (300, 3)\n",
      "        observation key ee_pos with shape (300, 3)\n",
      "        observation key ee_states with shape (300, 6)\n",
      "        observation key eye_in_hand_rgb with shape (300, 128, 128, 3)\n",
      "        observation key gripper_states with shape (300, 2)\n",
      "        observation key joint_states with shape (300, 7)\n",
      "    key: rewards with shape (300,)\n",
      "    key: robot_states with shape (300, 9)\n",
      "    key: states with shape (300, 47)\n",
      "episode demo_45 with 375 transitions\n",
      "    key: actions with shape (375, 7)\n",
      "    key: dones with shape (375,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (375, 128, 128, 3)\n",
      "        observation key ee_ori with shape (375, 3)\n",
      "        observation key ee_pos with shape (375, 3)\n",
      "        observation key ee_states with shape (375, 6)\n",
      "        observation key eye_in_hand_rgb with shape (375, 128, 128, 3)\n",
      "        observation key gripper_states with shape (375, 2)\n",
      "        observation key joint_states with shape (375, 7)\n",
      "    key: rewards with shape (375,)\n",
      "    key: robot_states with shape (375, 9)\n",
      "    key: states with shape (375, 47)\n",
      "episode demo_46 with 256 transitions\n",
      "    key: actions with shape (256, 7)\n",
      "    key: dones with shape (256,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (256, 128, 128, 3)\n",
      "        observation key ee_ori with shape (256, 3)\n",
      "        observation key ee_pos with shape (256, 3)\n",
      "        observation key ee_states with shape (256, 6)\n",
      "        observation key eye_in_hand_rgb with shape (256, 128, 128, 3)\n",
      "        observation key gripper_states with shape (256, 2)\n",
      "        observation key joint_states with shape (256, 7)\n",
      "    key: rewards with shape (256,)\n",
      "    key: robot_states with shape (256, 9)\n",
      "    key: states with shape (256, 47)\n",
      "episode demo_47 with 248 transitions\n",
      "    key: actions with shape (248, 7)\n",
      "    key: dones with shape (248,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (248, 128, 128, 3)\n",
      "        observation key ee_ori with shape (248, 3)\n",
      "        observation key ee_pos with shape (248, 3)\n",
      "        observation key ee_states with shape (248, 6)\n",
      "        observation key eye_in_hand_rgb with shape (248, 128, 128, 3)\n",
      "        observation key gripper_states with shape (248, 2)\n",
      "        observation key joint_states with shape (248, 7)\n",
      "    key: rewards with shape (248,)\n",
      "    key: robot_states with shape (248, 9)\n",
      "    key: states with shape (248, 47)\n",
      "episode demo_48 with 267 transitions\n",
      "    key: actions with shape (267, 7)\n",
      "    key: dones with shape (267,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (267, 128, 128, 3)\n",
      "        observation key ee_ori with shape (267, 3)\n",
      "        observation key ee_pos with shape (267, 3)\n",
      "        observation key ee_states with shape (267, 6)\n",
      "        observation key eye_in_hand_rgb with shape (267, 128, 128, 3)\n",
      "        observation key gripper_states with shape (267, 2)\n",
      "        observation key joint_states with shape (267, 7)\n",
      "    key: rewards with shape (267,)\n",
      "    key: robot_states with shape (267, 9)\n",
      "    key: states with shape (267, 47)\n",
      "episode demo_49 with 295 transitions\n",
      "    key: actions with shape (295, 7)\n",
      "    key: dones with shape (295,)\n",
      "    key: obs\n",
      "        observation key agentview_rgb with shape (295, 128, 128, 3)\n",
      "        observation key ee_ori with shape (295, 3)\n",
      "        observation key ee_pos with shape (295, 3)\n",
      "        observation key ee_states with shape (295, 6)\n",
      "        observation key eye_in_hand_rgb with shape (295, 128, 128, 3)\n",
      "        observation key gripper_states with shape (295, 2)\n",
      "        observation key joint_states with shape (295, 7)\n",
      "    key: rewards with shape (295,)\n",
      "    key: robot_states with shape (295, 9)\n",
      "    key: states with shape (295, 47)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <video width=\"640\" height=\"480\" controls>\n",
       "        <source src=\"output.mp4\" type=\"video/mp4\">\n",
       "    </video>\n",
       "    <script>\n",
       "        var video = document.getElementsByTagName('video')[0];\n",
       "        video.playbackRate = 2.0; // Increase the playback speed to 2x\n",
       "        </script>    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "from libero.libero.utils.dataset_utils import get_dataset_info\n",
    "from IPython.display import HTML\n",
    "import imageio\n",
    "\n",
    "example_demo_file = demo_files[9]\n",
    "# Print the dataset info. We have a standalone script for doing the same thing available at `scripts/get_dataset_info.py`\n",
    "get_dataset_info(example_demo_file)\n",
    "\n",
    "with h5py.File(example_demo_file, \"r\") as f:\n",
    "    images = f[\"data/demo_0/obs/agentview_rgb\"][()]\n",
    "\n",
    "video_writer = imageio.get_writer(\"output.mp4\", fps=60)\n",
    "for image in images:\n",
    "    video_writer.append_data(image[::-1])\n",
    "video_writer.close()\n",
    "\n",
    "HTML(\"\"\"\n",
    "    <video width=\"640\" height=\"480\" controls>\n",
    "        <source src=\"output.mp4\" type=\"video/mp4\">\n",
    "    </video>\n",
    "    <script>\n",
    "        var video = document.getElementsByTagName('video')[0];\n",
    "        video.playbackRate = 2.0; // Increase the playback speed to 2x\n",
    "        </script>    \n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Concate multiple datasets for multit-task training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tasks in the benchmark libero_10: 10\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import ConcatDataset, Dataset\n",
    "from libero.lifelong.datasets import get_dataset, SequenceVLDataset\n",
    "\n",
    "num_tasks = benchmark_instance.get_num_tasks()\n",
    "print(f\"Number of tasks in the benchmark {benchmark_instance.name}: {num_tasks}\")\n",
    "\n",
    "# manip_datasets = []\n",
    "# for demo_file in demo_files:\n",
    "#     task_i_dataset, shape_meta = get_dataset(\n",
    "#             dataset_path=os.path.join(cfg.folder,\n",
    "#                                         benchmark.get_task_demonstration(i)),\n",
    "#             obs_modality=cfg.data.obs.modality,\n",
    "#             initialize_obs_utils=(i==0),\n",
    "#             seq_len=cfg.data.seq_len)    \n",
    "#     manip_datasets.append()\n",
    "\n",
    "# concat_dataset = ConcatDataset([get_dataset(demo_file) for demo_file in demo_files])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Create datasets for Experience Replay algorithm\n",
    "\n",
    "In the algorithm of ER, we need to sample data from both dataset of the current task and data from previous experiences. To this end, a specific implementation is needed (`TruncatedSequenceDataset`)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "libero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
